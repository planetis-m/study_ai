{
  "Name": "TeachingAssistantSlideEvaluation",
  "Description": "Test cases for evaluating a teaching assistant's ability to extract and explain key information from slide content.",
  "Evaluators": ["Groundedness"],
  "Messages": [
    {
      "Role": "system",
      "Text": "You are an expert teaching assistant. You identify and explain key information from slide decks for exam preparation. You only work with the content provided and do not add external information, examples, or anecdotes. Write in a clear, informative style that helps students thoroughly understand the material, not just memorize bullet points. Organize your output with proper formatting and structure. Do not include introductory or concluding remarks."
    },
    {
      "Role": "user",
      "Text": "Identify the key topics presented in the following slide content. For each key topic, provide:\n- A detailed explanation of the concept\n- The essential facts or definitions students need for the final exam"
    }
  ],
  "TestCases": [
    {
      "TestId": "relational-model-section-1",
      "Description": "Testing key topic identification, explanation, and essential facts extraction from the 'The Relational Data Model' slide section.",
      "GroundingContext": "### Lecture 5: Distributed Databases (NoSQL)\n\n#### Lecture Outline\n- RDBMS ACID properties (the \u201Cgood\u201D and \u201Cbad\u201D things...)\n- The \u201Cbirth\u201D of NoSQL databases\n- The CAP Theorem\n- Key-value and wide-column data stores\n- Document stores\n- Graph stores\n\n#### The Relational Data Model\n- **Modeling the Course Management System**\n  - Logical Schema\n  - Data organized into relations (tables in SQL), where each is an unordered collection of tuples (rows in SQL) describing the entities participating in the relation.\n    - Students(sid: string, name: string, gpa: float)\n    - Courses(cid: string, cname: string, credits: int)\n    - Enrolled(sid: string, cid: string, grade: string)\n  - Factor for its success... Data Independence, hide implementation details (e.g., how and where the data is stored on disk) behind a cleaner interface.\n\n#### The Mantra - a DBMS must be...\n- Efficient, reliable, convenient, and provide safe multi-user persistent storage and access to data\n\n#### RDBMS Playbook \u2013 The ACID Properties\n- **Transactions (requests embedding 1\u002B queries) must be:**\n  - **Atomic:** The DB state reflects either all the effects of a TXN, or none of them.\n  - **Consistent:** A TXN moves from a state where data (and schema) integrity holds, to another where the integrity of the data is not affected.\n  - **Isolated:** The effect of a TXN is the same as TXNs running after one another even if they are run in parallel (increase DB efficiency).\n  - **Durable:** Once a TXN is committed, its effects remain in the database (e.g., not lost after a server reboot).\n\n#### Consistency Levels\n- **Strict:** The changes to the data are atomic and appear to take effect instantaneously (i.e., stop till all receive update). This is the highest form of consistency.\n- **Sequential:** Every client sees all changes in the same order they were applied.\n- **Causal:** All changes that are causally related are observed in the same order by all clients.\n- **Eventual:** When no updates occur for a period of time, eventually all updates will propagate through the system and all replicas (db nodes) will be consistent.\n- **Weak:** No guarantee is made that all updates will propagate and changes may appear out of order to various clients.\n\n#### The Birth of NoSQL\n- The term NoSQL \u2013short for Not Only SQL\u2013 was born in the 2010s as an attempt to overcome shortcomings of the relational model:\n  - Overcome frustration with the restrictiveness of the relational schemas and a desire for dynamic and flexible data models (often wrongfully dubbed as schemaless).\n  - A need for specialized query operations (e.g., analytics, graphs, ML, GenAI!!!)\n  - A need for greater scalability (e.g., large datasets with high read/write throughput)\n  - A need for relaxed consistency leading to even higher performance and availability\n- **But... nothing comes for free:**\n  - NoSQL DBs usually do NOT have a declarative query language -\u003E this means (much) more programming from the developer.\n  - Horizontally distributing data (and queries) enables greater scalability BUT too much distribution can accumulate large communication overheads.\n  - Relaxed consistency -\u003E this means fewer guarantees despite data being eventually consistent (e.g., financial transactions cannot have ambiguity).\n\n#### Schema Flexibility\n- NoSQL DBs, especially document stores, are often dubbed schemaless.\n- The term is misleading as it does not refer to the absence of structure (e.g., data model) but rather that the schema is not enforced by the DB.\n- A more accurate term is schema-on-read, meaning the structure of the data is implicit and interpreted on read (e.g., by the application requesting it).\n- In contrast, relational DBs are schema-on-write, meaning the schema is explicit and the DB ensures all written data conforms to it.\n\n#### NoSQL DBs \u201CPrefer\u201D BASE Instead of ACID\n- Amazon in 2007 (DynamoDB) pioneered the idea of eventual consistency to achieve greater availability and scalability.\n- Data fetched are not guaranteed to be up-to-date, but updates \u2013given enough time\u2013 are guaranteed to be propagated to all nodes eventually.\n- BASE = Basically Available, Soft state, Eventually consistent\n\n#### Eric Brewer\u2019s CAP Theorem (PODC, 2002)\n- A distributed system is not possible to guarantee all three of the following properties simultaneously:\n  - High Availability\n  - and Performance\n\n#### CAP Theorem for NoSQL\n- **What the CAP theorem really says:**\n  - If you cannot limit the number of faults and requests can be redirected and you insist on serving every request you receive then you cannot possibly be consistent.\n- **How the CAP theorem is interpreted:**\n  - You must always give something up: consistency, availability or fault-tolerance.\n\n#### The Key-Value Data Model\n- Data model: \u003Ckey,value\u003E pairs\n- Keys must be unique but values can be literally anything.\n- Basic operations:\n  - boolean insert(key, val)\n  - valueType fetch(key)\n  - boolean update(key, value)\n  - boolean delete(key)\n\n#### Fragmentation (Sharding)\n- One table... Split into multiple pieces... Need a way to find on which node is each tablet\n\n#### Replication for High Availability... and Fast Reads!\n- **Cassandra:**\n  - Factor (# copies)\n  - R/W Rule: One, Quorum, All\n  - Policy (e.g., Rack Unaware, Rack Aware, ...)\n  - Read all copies (return fastest reply, do repairs if necessary)\n- **HBase:** Does not manage replication, relies on HDFS\n\n#### Row Stores\n- Row stores must \u201Cfetch\u201D entire row into memory for query operator (i.e., selection) to be processed.\n- A single row can capture a lot of attributes (e.g., CY telco customer table has 212 attributes).\n- So... before we optimize a query with \u201Cpush-downs\u201D, we have a huge penalty just to \u201Cread\u201D the data and bring it to memory (cant read \u201Chalf\u201D a row).\n\n#### Column Stores\n- With column-stores, only the attributes needed are read.\n- So if a query only needs 4-5 attributes (i.e, from 212) then we only fetch to memory those.\n- But... \u201CSELECT * FROM...\u201D queries are not faster and may even be slower.\n- Some DBs don\u2019t allow SELECT *...\n\n#### Column vs Row Storage Layout\n- Column Store\n  - columns can be processed in parallel\n  - vectorization (COMP-240!!!)\n\n#### Column-Stores Achieve High Compression Rates\n- Besides loading to memory only the columns required for a query, we can further reduce disk throughput (IOs) by compressing data.\n- Rows contain values from different domains -\u003E more entropy meaning difficult to dense-pack (1:3).\n- Columns compress better -\u003E values are homogeneous.\n- Compression ratio can reach 1:10 (integers, booleans).\n\n#### Bitmap Encoding (Compression technique)\n- Works well when # of distinct values in a column is small compared to the # of rows. FB 2B\u002B users, but... country column approx. 200 distinct values.\n- A column with n distinct values is turned into n bitmaps: one for each distinct value, with one bit for each row.\n  - The bit is 1 if the row has that value and 0 if not.\n\n#### Run-Length Encoding\n- Bitmap encoding works, but if n is large then there will be a lot of zeros in most bitmaps.\n- Run-length encoding collapses sequence values that are the same (usually 0\u2019s and 1\u2019s).\n\n#### Bitmap Indexes\n- Bitmap indexes are very well suited for the queries that are common in a data warehouse (e.g., user/product exists, etc).\n- For example:\n  \u0060\u0060\u0060sql\n  SELECT product_name, unit_price FROM products\n  WHERE productID IN (30, 68, 69)\n  \u0060\u0060\u0060\n  - Load the bitmaps for products with id\u2019s 30, 68, and 69, and calculate the bitwise OR of the three bitmaps, which can be done very efficiently.\n\n#### RDMS Relation Normalization\n- The RDBMSes embrace normalization, meaning they avoid the existence of duplicate data.\n- How? by linking through relations multiple entities, and allowing for data in the database to grow independently of each other.\n- Big Data trade-off... when queries get more complex we need joins since we must be able to find data from multiple relations (aka performance plump).\n\n#### Relation Denormalization (Deduplication)\n- KV and document stores design principle... \u201Cwe embrace denormalization\u201D\n- It\u2019s ok to keep multiple copies of values if you can AVOID dreadful joins.\n- You can also keep (almost) everything in one place if it has meaning.\n- Who does this? Cassandra, BigTable, Google BigQuery, Pandas DataFrames...\n\n#### Data Deduplication Challenge\n- Free-text input\n- Ambiguity... Nicosia/Lefkosia and Athens Greece/Georgia, US\n- Duplication... if you have 400K users from Nicosia then you are storing \u201CNicosia\u201D 400K times in the DB!\n- When information is duplicated, all redundant copies must be updated in case of a change.\n- Standardized selections (drop-downs in UI)\n- Text mapped to reference (e.g., ID) in the background and then stored in DB... so here we end up with some normalization.\n\n#### Document Stores\n- **Impedance Mismatch (aka Object-Relation Mismatch)**\n  - Most application development today is done in object-oriented programming languages, which leads to a common criticism of the SQL data model: if data is stored in relational tables, an awkward translation layer is required between the objects in the application code and the database model of tables, rows, and columns...\n  - Let\u2019s consider a CV, or even better a LinkedIn profile, as a running example.\n\n- **Data model:** \u003Ckey,document\u003E pairs\n  - Documents can be JSON, XML or other formats.\n  - Basic operations:\n    - boolean insert(key, doc)\n    - document fetch(key)\n    - boolean update(key, doc)\n    - boolean delete(key)\n  - Collection of complex documents with arbitrary, nested data formats and varying \u201Crecord\u201D format\n\n- **Document Stores vs RDBMs**\n  - Document Stores avoid joins that come from:\n    - Many-to-One relationships\n    - Many-to-Many relationships\n\n- **Many-to-One Relationships**\n  - The JSON representation has better locality than the multi-table schema.\n  - If you want to fetch a profile in the relational example, you need to either perform multiple queries (query each table by user_id) or perform a messy multi-way join between the users table and its subordinate tables.\n  - In the JSON representation, all the relevant information is in one place, and one query is sufficient.\n\n- **Many-to-Many Relationships**\n  - Can we also support Many-to-Many relationships so that organizations and even schools are searchable with information available for them?\n  - If we use Reference IDs then positions and organizations, even locations, can separate entities /referencing other tree structures.\n  - So... now trees can connect with other trees!\n  - Try to avoid cycles!\n\n#### Graph Databases\n- If your app presents highly inter-connected data -\u003E many-to-many relations:\n  - Use a document-store and continuously \u201Cnormalize\u201D many-to-many relationships (i.e., connecting trees).\n  - Use an RDBMS with multiple tables referencing each other.\n  - Model your data as a graph!\n  - A graph consists of vertices (nodes or entities) and edges (links or arcs).\n  - Social graphs, web graph, road/traffic networks, etc.\n\n- **The Property Data Model**\n  - Each vertex consists of:\n    - A unique identifier\n    - A set of outgoing edges\n    - A set of incoming edges\n    - A collection of properties (key-value pairs)\n  - Each edge consists of:\n    - A unique identifier\n    - The vertex at which the edge starts (the tail vertex)\n    - The vertex at which the edge ends (the head vertex)\n    - A label for the relationship between the two vertices\n    - A collection of properties (key-value pairs)\n  - Any vertex can have an edge connecting it with any other vertex. No schema limitations.\n\n- **Representing a Property Graph using a RM**\n  \u0060\u0060\u0060sql\n  CREATE TABLE vertices (\n    vertex_id integer PRIMARY KEY,\n    properties json\n  );\n  CREATE TABLE edges (\n    edge_id integer PRIMARY KEY,\n    tail_vertex integer REFERENCES vertices (vertex_id),\n    head_vertex integer REFERENCES vertices (vertex_id),\n    label text,\n    properties json\n  );\n  CREATE INDEX edges_tails ON edges (tail_vertex);\n  CREATE INDEX edges_heads ON edges (head_vertex);\n  \u0060\u0060\u0060\n  - Some important aspects of this model are:\n    - Any vertex can have an edge connecting it with any other vertex. There is no schema that restricts which kinds of things can or cannot be associated.",
      "Tags": ["relational-model", "database-fundamentals", "nosql-lecture-context"]
    }
  ]
}
